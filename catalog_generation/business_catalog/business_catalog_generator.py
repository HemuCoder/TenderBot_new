# -*- coding: utf-8 -*-
"""
@File    : business_catalog_generator.py
@Description: This file contains the logic for generating the business catalog.
@Author  : <<your name>>
@Date    : <<date>>
@Version : 1.0
"""

# Input: Optional format framework (can be read from file if None).
# Output: SSE events indicating the progress and result of the business catalog generation.

import json
from typing import Dict, Any, List, AsyncGenerator, Tuple
import re
import uuid
import datetime

from fastmcp import Client as MCPClient

from ..config import settings
from ..utils.mcp_utils import sse, mcp_read_file, mcp_smart_write, call_llm_streaming
from ..utils.file_utils import (
    extract_business_section,
    collect_leaf_nodes_with_path,
    extract_json_from_response,
    extract_section,
    parse_requirement_blocks,
    find_and_add_node,
    find_and_update_node,
    assign_ids_and_levels,
)
from .agents import (
    business_catalog_analysis_agent,
    business_catalog_children_generation_agent,
    catalog_matching_agent,
    directory_optimization_agent,
)
from ..linking.linker import run_template_linking_pipeline


async def generate_business_catalog_v2_event_generator(
    format_framework: List[Dict[str, Any]] = None,
    model_name: str = settings.DEFAULT_MODEL_NAME,
    language: str = "zh"
) -> AsyncGenerator[str, None]:
    """
    Èò∂ÊÆµ2ÔºöÁîüÊàêÂïÜÂä°ÁõÆÂΩï V2„ÄÇ
    """
    mcp_client = MCPClient(settings.MCP_SERVER_URL)
    
    try:
        yield sse("phase_start", {"name": "ÁîüÊàêÂïÜÂä°ÁõÆÂΩï"})
        
        # 1. ËØªÂèñ format_framework.json
        if format_framework is None:
            async with mcp_client:
                framework_content = await mcp_read_file(mcp_client, settings.OUTPUT_PATHS["format_framework"])
            if not framework_content:
                yield sse("error", {"message": "Êó†Ê≥ïËØªÂèñÊ†ºÂºèÊ°ÜÊû∂Êñá‰ª∂ÔºåËØ∑ÂÖàÊâßË°åÊ†ºÂºèÊ°ÜÊû∂ÊèêÂèñ"})
                return
            try:
                format_framework = json.loads(framework_content)
            except json.JSONDecodeError:
                yield sse("error", {"message": "Ê†ºÂºèÊ°ÜÊû∂Êñá‰ª∂Ê†ºÂºèÈîôËØØ"})
                return
        
        business_framework = extract_business_section(format_framework)
        if not business_framework:
            yield sse("warning", {"phase": "ÂïÜÂä°ÁõÆÂΩïÁîüÊàê", "text": "Êú™Âú®Ê†ºÂºèÊ°ÜÊû∂‰∏≠ÊâæÂà∞ÂïÜÂä°ÈÉ®ÂàÜ„ÄÇ"})
            return
        
        # ==============================================================================
        # Ê≠•È™§1ÔºöÈÄêÈ°πÂàÜÊûêÂπ∂ÁîüÊàêÂ≠êÁõÆÂΩï
        # ==============================================================================
        yield sse("phase_start", {"name": "Ê≠•È™§1: ÈÄêÈ°πÂàÜÊûêÂπ∂ÁîüÊàêÂ≠êÁõÆÂΩï"})
        
        leaf_nodes = collect_leaf_nodes_with_path(business_framework)
        
        if not leaf_nodes:
            yield sse("warning", {"phase": "ÂïÜÂä°ÁõÆÂΩïÁîüÊàê", "text": "Êú™ÊâæÂà∞Âè∂Â≠êËäÇÁÇπÔºåË∑≥ËøáÂ§ÑÁêÜ„ÄÇ"})
            yield sse("phase_end", {"name": "Ê≠•È™§1: ÈÄêÈ°πÂàÜÊûêÂπ∂ÁîüÊàêÂ≠êÁõÆÂΩï"})
            yield sse("phase_end", {"name": "ÂïÜÂä°ÁõÆÂΩïÁîüÊàêÔºàÈáçÊûÑÁâàÔºâ"})
            yield sse("complete", {"final_output": "ÂïÜÂä°ÁõÆÂΩïÁîüÊàêÂÆåÊàêÔºàÊó†ÈúÄÂ§ÑÁêÜÔºâ"})
            return
        
        yield sse("note", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"ËØÜÂà´Âà∞ {len(leaf_nodes)} ‰∏™Âè∂Â≠êËäÇÁÇπÔºåÂºÄÂßãÈÄêÈ°πÂ§ÑÁêÜ..."})
        
        analysis_agent = business_catalog_analysis_agent(language=language)
        analysis_system_prompt = analysis_agent.instructions
        children_gen_agent = business_catalog_children_generation_agent(language=language)
        children_system_prompt = children_gen_agent.instructions
        
        for idx, node_info in enumerate(leaf_nodes, 1):
            node_name = node_info['name']
            node = node_info['node']
            
            yield sse("update", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "progress": f"{idx}/{len(leaf_nodes)}"})
            
            content_desc = node.get('content_description', '')
            if not content_desc:
                yield sse("note", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚û°Ô∏è ({idx}/{len(leaf_nodes)}) Ë∑≥ËøáÔºàÊó†ÊèèËø∞Ôºâ: {node_name}"})
                continue
            
            analysis_input = f"""# ÁõÆÂΩïÈ°πÔºö
{json.dumps({'name': node_name, 'children': []}, ensure_ascii=False, indent=2)}

# ËØ•ÁõÆÂΩïÁöÑÂÜÖÂÆπÊèèËø∞Ôºö
{content_desc}

ËØ∑ÊåâÁÖßË¶ÅÊ±ÇÁîüÊàêÂàÜÊûêÊä•Âëä„ÄÇ"""
            
            md_analysis = ""
            try:
                log_id = f"log-{uuid.uuid4()}"
                yield sse("debug_log", {"title": f"ÂàÜÊûêÂÜÖÂÆπ ({idx}/{len(leaf_nodes)}): {node_name}", "log_id": log_id})

                async for item in call_llm_streaming(
                    system_prompt=analysis_system_prompt,
                    user_input=analysis_input,
                    model_name=model_name,
                    yield_tokens=True
                ):
                    if 'event: token_delta' in item:
                        try:
                            data_line = next(line for line in item.split('\n') if line.startswith('data: '))
                            data = json.loads(data_line[len('data: '):])
                            delta = data.get('delta', '')
                            if delta:
                                md_analysis += delta
                                yield sse("debug_token_delta", {"log_id": log_id, "delta": delta})
                        except (StopIteration, json.JSONDecodeError):
                            pass
            except Exception as e:
                yield sse("warning", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚ö†Ô∏è ({idx}/{len(leaf_nodes)}) ÂàÜÊûêÂ§±Ë¥•: {node_name} - {str(e)}"})
                continue
            
            children_input = f"""# ÂΩìÂâçÂàÜÊûêÁöÑÁõÆÂΩïÂØπË±°Ôºö
            {json.dumps({'name': node_name, 'children': [], 'content_description': content_desc}, ensure_ascii=False, indent=2)}

            # ËØ•ÁõÆÂΩïÁöÑËØ¶ÁªÜÂàÜÊûêÊä•ÂëäÔºö
            {md_analysis}

            ËØ∑Âà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅÊ∑ªÂä†Â≠êÁõÆÂΩïÔºåÂπ∂ÊåâÁÖßË¶ÅÊ±ÇËæìÂá∫„ÄÇ"""

            children_response = ""
            try:
                log_id = f"log-{uuid.uuid4()}"
                yield sse("debug_log", {"title": f"ÁîüÊàêÂ≠êÁõÆÂΩï ({idx}/{len(leaf_nodes)}): {node_name}", "log_id": log_id})
                async for item in call_llm_streaming(
                    system_prompt=children_system_prompt,
                    user_input=children_input,
                    model_name=model_name,
                    yield_tokens=True
                ):
                    if 'event: token_delta' in item:
                        try:
                            data_line = next(line for line in item.split('\n') if line.startswith('data: '))
                            data = json.loads(data_line[len('data: '):])
                            delta = data.get('delta', '')
                            if delta:
                                children_response += delta
                                yield sse("debug_token_delta", {"log_id": log_id, "delta": delta})
                        except (StopIteration, json.JSONDecodeError):
                            pass
            except Exception as e:
                yield sse("warning", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚ö†Ô∏è ({idx}/{len(leaf_nodes)}) Â≠êÁõÆÂΩïÁîüÊàêÂ§±Ë¥•: {node_name} - {str(e)}"})
                continue
            
            if "NO_CHILDREN" in children_response.strip():
                yield sse("note", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚û°Ô∏è ({idx}/{len(leaf_nodes)}) ‰∏çÈúÄË¶ÅÂ≠êÁõÆÂΩï: {node_name}"})
                continue
            
            try:
                children_json_str = extract_json_from_response(children_response)
                children_data = json.loads(children_json_str)
                
                if not isinstance(children_data, list):
                    yield sse("warning", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚ö†Ô∏è ({idx}/{len(leaf_nodes)}) ËøîÂõûÊ†ºÂºèÈîôËØØÔºàÈùûÊï∞ÁªÑÔºâ: {node_name}"})
                    continue
            
                node['children'] = children_data
                yield sse("note", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚úÖ ({idx}/{len(leaf_nodes)}) Â∑≤Ê∑ªÂä† {len(children_data)} ‰∏™Â≠êÁõÆÂΩï: {node_name}"})
                
            except json.JSONDecodeError as e:
                yield sse("warning", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": f"‚ö†Ô∏è ({idx}/{len(leaf_nodes)}) JSON Ëß£ÊûêÂ§±Ë¥•: {node_name} - {str(e)}"})
                continue
        
        yield sse("note", {"phase": "ÂàÜÊûêÂπ∂ÁîüÊàê", "text": "ÊâÄÊúâÂè∂Â≠êËäÇÁÇπÂ§ÑÁêÜÂÆåÊàê"})
        yield sse("phase_end", {"name": "Ê≠•È™§1: ÈÄêÈ°πÂàÜÊûêÂπ∂ÁîüÊàêÂ≠êÁõÆÂΩï"})

        # ‰øùÂ≠òÊ≠•È™§1ÁªìÊùüÂêéÁöÑ‰∏≠Èó¥Êñá‰ª∂
        intermediate_catalog_json = json.dumps(business_framework, ensure_ascii=False, indent=2)
        async with mcp_client:
            await mcp_smart_write(
                mcp_client,
                settings.OUTPUT_PATHS["business_catalog_intermediate"],
                intermediate_catalog_json
            )
        yield sse("artifact", {"type": "file", "filename": settings.OUTPUT_PATHS["business_catalog_intermediate"]})


        # ==============================================================================
        # Ê≠•È™§2ÔºöÈúÄÊ±ÇÈ™åËØÅ‰∏éÁõÆÂΩï‰ºòÂåñ
        # ==============================================================================
        
        try:
            async with mcp_client:
                checklist_content = await mcp_read_file(mcp_client, settings.INPUT_PATHS["final_checklist"])
            
            if checklist_content:
                check_section = extract_section(checklist_content, "ÂïÜÂä°ÈÉ®ÂàÜËØÑÂàÜ")
                requirement_blocks = parse_requirement_blocks(check_section) if check_section else []
                
                if requirement_blocks:
                    yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"ËØÜÂà´Âà∞ {len(requirement_blocks)} ‰∏™ÈúÄÊ±ÇÂùóÔºåÂºÄÂßãÈ™åËØÅ..."})
                    
                    matching_agent = catalog_matching_agent(language=language)
                    matching_system_prompt = matching_agent.instructions
                    
                    verification_report_full = "# ÂïÜÂä°ÁõÆÂΩïÈúÄÊ±ÇÈ™åËØÅÊä•Âëä\n\n"
                    
                    for idx, req_block in enumerate(requirement_blocks, 1):
                        yield sse("update", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "progress": f"{idx}/{len(requirement_blocks)}"})
                        
                        verification_input = f"""ÂΩìÂâçÈúÄË¶ÅÂà§Êñ≠ÁöÑÈúÄÊ±ÇÔºö
                        {req_block}

                        ÂΩìÂâçÁöÑÁõÆÂΩïÊòØÔºö
                        {json.dumps(business_framework, ensure_ascii=False, indent=2)}
                        """
                            
                        try:
                            matching_analysis = ""
                            log_id = f"log-{uuid.uuid4()}"
                            yield sse("debug_log", {"title": f"ÈúÄÊ±ÇÈ™åËØÅ ({idx}/{len(requirement_blocks)})", "log_id": log_id})
                            
                            async for item in call_llm_streaming(
                                system_prompt=matching_system_prompt,
                                user_input=verification_input,
                                model_name=model_name,
                                yield_tokens=True
                            ):
                                if 'event: token_delta' in item:
                                    try:
                                        data_line = next(line for line in item.split('\n') if line.startswith('data: '))
                                        data = json.loads(data_line[len('data: '):])
                                        delta = data.get('delta', '')
                                        if delta:
                                            matching_analysis += delta
                                            yield sse("debug_token_delta", {"log_id": log_id, "delta": delta})
                                    except (StopIteration, json.JSONDecodeError):
                                        pass
            
                            if "IRRELEVANT_REQUIREMENT" in matching_analysis:
                                yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"‚û°Ô∏è ({idx}/{len(requirement_blocks)}) Ë∑≥ËøáÊó†ÂÖ≥ÈúÄÊ±Ç"})
                                verification_report_full += f"{'='*80}\n"
                                verification_report_full += f"## ÈúÄÊ±Ç {idx}/{len(requirement_blocks)}\n\n"
                                verification_report_full += f"### ÈúÄÊ±ÇÂÜÖÂÆπ\n```\n{req_block[:200]}{'...' if len(req_block) > 200 else ''}\n```\n\n"
                                verification_report_full += f"**Áä∂ÊÄÅ**: ‚è≠Ô∏è Ë∑≥Ëøá (Êó†ÂÖ≥ÈúÄÊ±Ç)\n\n"
                                continue
                            
                            verification_report_full += f"{'='*80}\n"
                            verification_report_full += f"## ÈúÄÊ±Ç {idx}/{len(requirement_blocks)}\n\n"
                            verification_report_full += f"### ÈúÄÊ±ÇÂÜÖÂÆπ\n```\n{req_block[:200]}{'...' if len(req_block) > 200 else ''}\n```\n\n"
                            verification_report_full += f"### È™åËØÅÁªìÊûú\n\n{matching_analysis}\n\n"
                            
                            yield sse("stream_start", {"phase": "ÁõÆÂΩï‰ºòÂåñ", "current": f"ÈúÄÊ±Ç {idx} - ÊâßË°å‰ºòÂåñ"})
                            
                            optimization_input = f"""# ÈúÄÊ±ÇÂàÜÊûê‰∏éÊìç‰ΩúÂª∫ËÆÆ

{matching_analysis}

# ÂΩìÂâçÁõÆÂΩïÁªìÊûÑ
{json.dumps(business_framework, ensure_ascii=False, indent=2)}

# ‰Ω†ÁöÑ‰ªªÂä°
Ê†πÊçÆ‰∏äÈù¢ÁöÑ"Êìç‰ΩúÂª∫ËÆÆ"Ôºå‰ΩøÁî®Â∑•ÂÖ∑Êù•‰øÆÊîπÁõÆÂΩï„ÄÇ
- **Âè™ËæìÂá∫Â∑•ÂÖ∑Ë∞ÉÁî®**Ôºå‰∏çË¶ÅËæìÂá∫ÂÖ∂‰ªñ‰ªª‰ΩïÊñáÂ≠ó„ÄÇ
- Â¶ÇÊûúÈúÄË¶ÅÊñ∞Â¢ûÔºåËØ∑Ë∞ÉÁî® `add_catalog_child` Â∑•ÂÖ∑„ÄÇ
- Â¶ÇÊûúÈúÄË¶ÅÊõ¥Êñ∞ÔºåËØ∑Ë∞ÉÁî® `update_catalog_node` Â∑•ÂÖ∑„ÄÇ"""
                            
                            try:
                                optimization_agent = directory_optimization_agent()
                                optimization_response = ""
                                log_id = f"log-{uuid.uuid4()}"
                                yield sse("debug_log", {"title": f"ÁõÆÂΩï‰ºòÂåñ ({idx}/{len(requirement_blocks)})", "log_id": log_id})

                                async for item in call_llm_streaming(
                                    system_prompt=optimization_agent.instructions,
                                    user_input=optimization_input,
                                    model_name=model_name,
                                    yield_tokens=True
                                ):
                                    if 'event: token_delta' in item:
                                        try:
                                            data_line = next(line for line in item.split('\n') if line.startswith('data: '))
                                            data = json.loads(data_line[len('data: '):])
                                            delta = data.get('delta', '')
                                            if delta:
                                                optimization_response += delta
                                                yield sse("debug_token_delta", {"log_id": log_id, "delta": delta})
                                        except (StopIteration, json.JSONDecodeError):
                                            pass
                                
                                tool_calls_executed, execution_logs = _parse_and_execute_tool_calls(
                                    optimization_response,
                                    business_framework
                                )
                                
                                for log in execution_logs:
                                    if "‚úÖ" in log:
                                        log_summary = log.split("]")[1].strip() if "]" in log else log
                                        yield sse("note", {"phase": "ÁõÆÂΩï‰ºòÂåñ", "text": f"‚úÖ {log_summary}"})
                                        verification_report_full += f"- {log}\n"
                                    else:
                                        log_summary = log.split("]")[1].strip() if "]" in log else log
                                        yield sse("warning", {"phase": "ÁõÆÂΩï‰ºòÂåñ", "text": f"‚ùå {log_summary}"})
                                        verification_report_full += f"- {log}\n"
                                
                                if tool_calls_executed > 0:
                                    yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"üîß ({idx}/{len(requirement_blocks)}) Â∑≤Ê†πÊçÆÂàÜÊûê‰ºòÂåñÁõÆÂΩïÔºåÊâßË°å {tool_calls_executed} ‰∏™‰øÆÊîπ„ÄÇ"})
                                    verification_report_full += f"**Áä∂ÊÄÅ**: ‚úÖ Â∑≤‰ºòÂåñ\n"
                                    verification_report_full += f"**ÊâßË°åÁªìÊûú**: Â∑≤Ëá™Âä®‰ºòÂåñ {tool_calls_executed} Â§Ñ„ÄÇ\n\n"
                                else:
                                    yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"‚úÖ ({idx}/{len(requirement_blocks)}) ÈúÄÊ±ÇÂ∑≤Êª°Ë∂≥ÔºåÊó†ÈúÄ‰øÆÊîπ„ÄÇ"})
                                    verification_report_full += f"**Áä∂ÊÄÅ**: ‚úÖ Â∑≤Êª°Ë∂≥\n"
                                    verification_report_full += f"**ÊâßË°åÁªìÊûú**: AIÂàÜÊûêÂêéËÆ§‰∏∫Êó†ÈúÄ‰øÆÊîπ„ÄÇ\n\n"
                                
                            except Exception as opt_error:
                                yield sse("warning", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"‚ö†Ô∏è ({idx}/{len(requirement_blocks)}) ÁõÆÂΩï‰ºòÂåñÂ§±Ë¥•"})
                                
                        except Exception as e:
                            yield sse("warning", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"‚ö†Ô∏è ({idx}/{len(requirement_blocks)}) È™åËØÅÂ§±Ë¥•"})
                            
                            verification_report_full += f"{'='*80}\n"
                            verification_report_full += f"## ÈúÄÊ±Ç {idx}/{len(requirement_blocks)}\n\n"
                            verification_report_full += f"### ÈúÄÊ±ÇÂÜÖÂÆπ\n```\n{req_block[:200]}{'...' if len(req_block) > 200 else ''}\n```\n\n"
                            verification_report_full += f"### È™åËØÅÁªìÊûú\n\n‚ùå È™åËØÅÂ§±Ë¥•: {str(e)}\n\n"
                            verification_report_full += f"**Áä∂ÊÄÅ**: ‚ùå È™åËØÅÂ§±Ë¥•\n\n"
                    
                    verification_report_full += f"{'='*80}\n\n"
                    verification_report_full += "## È™åËØÅÊÄªÁªì\n\n"
                    verification_report_full += f"- ÊÄªÈúÄÊ±ÇÊï∞: {len(requirement_blocks)}\n"
                    verification_report_full += f"- Êä•ÂëäÂÆåÊàêÊó∂Èó¥: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n\n"
                    
                    async with mcp_client:
                        await mcp_smart_write(
                            mcp_client,
                            "catalog_verification_report.md",
                            verification_report_full
                        )
                    
                    yield sse("info", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": "üìÑ È™åËØÅÊä•ÂëäÂ∑≤‰øùÂ≠ò: catalog_verification_report.md"})
                    yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": "ÈúÄÊ±ÇÈ™åËØÅÂÆåÊàê"})
                else:
                    yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": "Êú™ÊâæÂà∞ÈúÄÊ±ÇÂùóÔºåË∑≥ËøáÈ™åËØÅ"})
            else:
                yield sse("note", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": "Êú™ÊâæÂà∞checklistÊñá‰ª∂ÔºåË∑≥ËøáÈ™åËØÅ"})
                
        except Exception as e:
            yield sse("warning", {"phase": "ÈúÄÊ±ÇÈ™åËØÅ", "text": f"È™åËØÅËøáÁ®ãÂá∫Èîô: {str(e)}"})
        
        yield sse("phase_end", {"name": "Ê≠•È™§2: ÈúÄÊ±ÇÈ™åËØÅ‰∏éÁõÆÂΩï‰ºòÂåñ"})
        
        def remove_analysis_report(nodes):
            for node in nodes:
                if 'analysis_report' in node:
                    del node['analysis_report']
                if node.get('children'):
                    remove_analysis_report(node['children'])
        
        remove_analysis_report(business_framework)
        
        assign_ids_and_levels(business_framework, prefix="bus")
        
        # 3. ‰øùÂ≠òÊúÄÁªàÁöÑÂïÜÂä°ÁõÆÂΩï
        final_catalog_json = json.dumps(business_framework, ensure_ascii=False, indent=2)
        async with mcp_client:
            await mcp_smart_write(
                mcp_client,
                settings.OUTPUT_PATHS["business_catalog"],
                final_catalog_json
            )
        
        yield sse("artifact", {"type": "file", "filename": settings.OUTPUT_PATHS["business_catalog"]})
        yield sse("phase_end", {"name": "ÁîüÊàêÂïÜÂä°ÁõÆÂΩï"})

        # ==============================================================================
        # Ê≠•È™§4: Ê®°ÊùøÂÖ≥ËÅî
        # ==============================================================================
        yield sse("phase_start", {"name": "Ê≠•È™§4: Ê®°ÊùøÂÖ≥ËÅî"})
        async for event in run_template_linking_pipeline(
            catalog_input_path=settings.OUTPUT_PATHS["business_catalog"],
            templates_input_path=settings.INPUT_PATHS["templates"],
            catalog_output_path=settings.OUTPUT_PATHS["business_catalog_linked"],
            language=language
        ):
            yield event
        yield sse("phase_end", {"name": "Ê≠•È™§4: Ê®°ÊùøÂÖ≥ËÅî"})

        yield sse("complete", {"final_output": "ÂïÜÂä°ÁõÆÂΩïÂèäÊ®°ÊùøÂÖ≥ËÅîÂ∑≤ÂÖ®ÈÉ®ÂÆåÊàêÔºÅ", "catalog": business_framework})
        
    except Exception as e:
        error_info = {"type": type(e).__name__, "message": str(e)}
        yield sse("error", error_info)
    finally:
        print("ÂïÜÂä°ÁõÆÂΩïÁîüÊàê‰ªªÂä°Â∑≤ÁªàÊ≠¢ÊàñÂÆåÊàê„ÄÇ")


def _parse_and_execute_tool_calls(
    response_text: str, 
    business_framework: List[Dict]
) -> Tuple[int, List[str]]:
    """
    ‰ªéLLMÁöÑÂìçÂ∫îÊñáÊú¨‰∏≠Ëß£ÊûêÂπ∂ÊâßË°åÁõÆÂΩïÁºñËæëÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®„ÄÇ
    """
    logs = []
    tool_calls_to_process = []

    try:
        data = json.loads(response_text)
        if isinstance(data, list):
            tool_calls_to_process = data
        elif isinstance(data, dict):
            tool_calls_to_process = [data]
    except json.JSONDecodeError:
        json_strings = re.findall(r'```json\s*([\s\S]*?)\s*```', response_text)
        if not json_strings:
            json_strings = re.findall(r'```\s*([\s\S]*?)\s*```', response_text)
        
        for block_str in json_strings:
            try:
                data = json.loads(block_str)
                if isinstance(data, list):
                    tool_calls_to_process.extend(data)
                else:
                    tool_calls_to_process.append(data)
            except json.JSONDecodeError:
                logs.append(f"‚ö†Ô∏è JSONËß£ÊûêÂ§±Ë¥•ÔºåË∑≥ËøáÂùó: {block_str[:100]}")
                continue

    tool_calls_executed = 0

    if not tool_calls_to_process:
        logs.append(f"üìã Êú™Âú®ÂìçÂ∫î‰∏≠Ëß£ÊûêÂà∞‰ªª‰ΩïÊúâÊïàÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®: {response_text[:200]}")
        return 0, logs

    for tool_call in tool_calls_to_process:
        if not isinstance(tool_call, dict):
            continue
        try:
            tool_name = tool_call.get("function") or tool_call.get("name") or tool_call.get("tool")
            args = tool_call.get("parameters") or tool_call.get("arguments") or tool_call.get("args") or tool_call.get("params") or {}
            if not args:
                args = tool_call

            if tool_name == "add_catalog_child":
                parent_path_raw = args.get("parent_catalog_path") or args.get("path") or args.get("parent_path")
                if isinstance(parent_path_raw, str):
                    parent_path = [p.strip() for p in parent_path_raw.split(">")]
                else:
                    parent_path = parent_path_raw
                
                node_data = args.get("new_child_catalog") or args.get("child") or args.get("new_catalog") or args.get("new_child")
                
                if not node_data:
                    child_name = args.get("child_name")
                    if child_name:
                        node_data = {"name": child_name, "children": [], "content_description": ""}

                if parent_path and node_data:
                    if find_and_add_node(business_framework, parent_path, node_data):
                        tool_calls_executed += 1
                        logs.append(f"‚úÖ [ADD] Âú® '{' > '.join(parent_path)}' ‰∏ãÊ∑ªÂä† '{node_data.get('name')}'")
                    else:
                        logs.append(f"‚ùå [ADD] Âú® '{' > '.join(parent_path)}' Ê∑ªÂä†Â§±Ë¥•")

            elif tool_name == "update_catalog_node":
                path_raw = args.get("catalog_path") or args.get("path") or args.get("target_path")
                if isinstance(path_raw, str):
                    path = [p.strip() for p in path_raw.split(">")]
                else:
                    path = path_raw

                description = args.get("content_description") or args.get("new_content_description")
                
                if path and description:
                    update_data = {"content_description": description}
                    if find_and_update_node(business_framework, path, update_data):
                        tool_calls_executed += 1
                        logs.append(f"‚úÖ [UPDATE] ÊàêÂäüÊõ¥Êñ∞ '{' > '.join(path)}'")
                    else:
                        logs.append(f"‚ùå [UPDATE] Êõ¥Êñ∞ '{' > '.join(path)}' Â§±Ë¥•")

        except Exception as exec_error:
            logs.append(f"‚ö†Ô∏è Â∑•ÂÖ∑Ë∞ÉÁî®ÊâßË°åÂ§±Ë¥•: {exec_error}")
            continue
            
    return tool_calls_executed, logs
