# -*- coding: utf-8 -*-
"""
============================================================
PIPELINE STAGES
æµæ°´çº¿å„é˜¶æ®µå®ç°
============================================================
"""

import json
import os
import time
import uuid
from typing import Any, AsyncGenerator
from fastmcp import Client as MCPClient

from .pipeline_core import PipelineStage, StageResult
from .utils.mcp_utils import sse, mcp_read_file, mcp_smart_write
from .config import settings
from .data_preprocessing.format_extractor import (
    extract_format_framework_event_generator,
    enrich_catalog_descriptions_event_generator
)
from .compensation.orchestrator import CompensationOrchestrator
from .compensation.classifier import CatalogClassifier


class FrameworkExtractionStage(PipelineStage):
    """é˜¶æ®µ1: æå–æ¡†æ¶"""
    
    def __init__(self, model: str, language: str):
        super().__init__("æå–æ ¼å¼æ¡†æ¶")
        self.model = model
        self.language = language
    
    async def _run(self, input_data: Any) -> AsyncGenerator:
        format_framework = None
        source_chunk = None
        
        # è°ƒç”¨åŸæœ‰çš„æå–é€»è¾‘
        gen = extract_format_framework_event_generator(
            model_name=self.model,
            language=self.language,
            return_source_chunk=True
        )
        
        async for event_str in gen:
            # è§£æå®Œæˆäº‹ä»¶,æå–æ•°æ®
            if 'event: complete' in event_str:
                try:
                    data_line = next(line for line in event_str.split('\n') 
                                   if line.startswith('data: '))
                    data_json = data_line[len('data: '):]
                    data = json.loads(data_json)
                    format_framework = data.get('framework')
                    source_chunk = data.get('source_chunk')
                except (StopIteration, json.JSONDecodeError):
                    pass
            else:
                yield event_str
        
        # è¿”å›ç»“æœ
        yield StageResult(
            data={
                "framework": format_framework,
                "source_chunk": source_chunk
            },
            metadata={"model": self.model, "language": self.language}
        )


class DescriptionEnrichmentStage(PipelineStage):
    """é˜¶æ®µ2: ä¸°å¯Œæè¿°"""
    
    def __init__(self, model: str, language: str):
        super().__init__("æ·»åŠ ç›®å½•å†…å®¹æè¿°")
        self.model = model
        self.language = language
    
    async def _run(self, input_data: Any) -> AsyncGenerator:
        framework = input_data.get("framework")
        source_chunk = input_data.get("source_chunk")
        
        if not framework or not source_chunk:
            yield self.warning("æœªèƒ½ä»ä¸Šä¸€é˜¶æ®µè·å–æœ‰æ•ˆæ¡†æ¶,è·³è¿‡æè¿°ç”Ÿæˆ")
            yield StageResult(data=input_data)
            return
        
        # è°ƒç”¨åŸæœ‰çš„ä¸°å¯Œæè¿°é€»è¾‘
        gen = enrich_catalog_descriptions_event_generator(
            format_framework=framework,
            source_chunk_text=source_chunk,
            model_name=self.model,
            language=self.language
        )
        
        enriched_framework = None
        async for event_str in gen:
            # è§£æå®Œæˆäº‹ä»¶
            if 'event: complete' in event_str:
                try:
                    data_line = next(line for line in event_str.split('\n') 
                                   if line.startswith('data: '))
                    data_json = data_line[len('data: '):]
                    data = json.loads(data_json)
                    enriched_framework = data.get('framework', framework)
                except (StopIteration, json.JSONDecodeError):
                    enriched_framework = framework
            else:
                yield event_str
        
        # è¿”å›ä¸°å¯Œåçš„æ¡†æ¶
        yield StageResult(
            data={
                "framework": enriched_framework or framework,
                "source_chunk": source_chunk
            }
        )


class CompensationStage(PipelineStage):
    """é˜¶æ®µ3: è¡¥å¿ä¸åˆ†ç±»"""
    
    def __init__(self):
        super().__init__("ç›®å½•è¡¥å¿ä¸åˆ†ç±»")
    
    async def _run(self, input_data: Any) -> AsyncGenerator:
        framework = input_data.get("framework")
        
        if not framework:
            yield self.warning("æ¡†æ¶æ•°æ®ä¸ºç©º,è·³è¿‡è¡¥å¿æµç¨‹")
            yield StageResult(data=input_data)
            return
        
        yield self.note(f"å¼€å§‹åˆ†æå’Œè¡¥å¿ç›®å½•ç»“æ„,å…± {len(framework)} ä¸ªé¡¶å±‚èŠ‚ç‚¹")
        yield self.note("ğŸ¤– ReAct Agent æ­£åœ¨åˆ†æç›®å½•ç»“æ„...")
        yield self.note("â³ è¿™å¯èƒ½éœ€è¦ 30-60 ç§’,è¯·è€å¿ƒç­‰å¾…...")
        
        # å‡†å¤‡æ—¥å¿—
        log_dir = os.path.join(settings._OUTPUT_DIR, "logs")
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, "compensation_log.txt")
        
        log_id = f"log-{uuid.uuid4()}"
        agent_logs = []
        
        yield sse("debug_log", {"title": "ReAct Agent æ¨ç†è¿‡ç¨‹", "log_id": log_id})
        
        def agent_log_callback(msg):
            agent_logs.append(msg)
        
        # æ‰§è¡Œè¡¥å¿
        orchestrator = CompensationOrchestrator()
        start_time = time.time()
        
        yield self.note(f"â±ï¸ å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
        
        result = await orchestrator.run(
            framework,
            log_file=log_file,
            log_callback=agent_log_callback
        )
        
        # è¾“å‡ºæ—¥å¿—
        if agent_logs:
            full_log = "\n".join(agent_logs)
            yield sse("debug_token_delta", {"log_id": log_id, "delta": full_log})
        
        elapsed = time.time() - start_time
        yield self.note(f"â±ï¸ å®Œæˆæ—¶é—´: {time.strftime('%H:%M:%S')} (è€—æ—¶ {elapsed:.1f}ç§’)")
        yield self.note("âœ… Agent åˆ†æå®Œæˆ!")
        
        compensated_framework = result["compensated_structure"]
        
        yield self.note(f"è¡¥å¿å®Œæˆ,æ¥æº: {result['source']}")
        yield self.note(f"æœ€ç»ˆç»“æ„: {len(compensated_framework)} ä¸ªé¡¶å±‚èŠ‚ç‚¹")
        
        # ä¿å­˜è¡¥å¿åçš„ç»“æ„
        compensated_path = os.path.join(settings._OUTPUT_DIR, "format_framework_compensated.json")
        
        async with MCPClient(settings.MCP_SERVER_URL) as mcp_client:
            await mcp_smart_write(
                mcp_client,
                compensated_path,
                json.dumps(compensated_framework, ensure_ascii=False, indent=2)
            )
        
        yield self.artifact(compensated_path)
        yield self.note("âœ… è¡¥å¿åçš„ç»“æ„å·²ä¿å­˜")
        
        # åˆ†ç±»ç”Ÿæˆä¸‰ä¸ªè§†å›¾
        yield self.note("ğŸ“‚ å¼€å§‹åˆ†ç±»ç”Ÿæˆå•†åŠ¡/æŠ€æœ¯/æŠ¥ä»·è§†å›¾...")
        
        classifier = CatalogClassifier()
        views = classifier.classify_and_split(compensated_framework)
        
        view_paths = {
            "business": os.path.join(settings._OUTPUT_DIR, "business_framework.json"),
            "technical": os.path.join(settings._OUTPUT_DIR, "technical_framework.json"),
            "pricing": os.path.join(settings._OUTPUT_DIR, "pricing_framework.json")
        }
        
        async with MCPClient(settings.MCP_SERVER_URL) as mcp_client:
            for view_type, view_data in views.items():
                view_path = view_paths[view_type]
                await mcp_smart_write(
                    mcp_client,
                    view_path,
                    json.dumps(view_data, ensure_ascii=False, indent=2)
                )
                
                node_count = len(view_data)
                yield self.artifact(view_path)
                yield self.note(f"âœ… {view_type.upper()} è§†å›¾: {node_count} ä¸ªé¡¶å±‚èŠ‚ç‚¹")
        
        yield self.note("ğŸ“‚ ä¸‰ä¸ªåˆ†ç±»è§†å›¾å·²ç”Ÿæˆå®Œæ¯•")
        
        # è¿”å›è¡¥å¿åçš„æ¡†æ¶
        yield StageResult(
            data={
                "framework": compensated_framework,
                "views": views
            }
        )
